{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import torch\n",
    "from shared import (\n",
    "    gpt,\n",
    "    tokenizer,\n",
    "    show_token_mapping,\n",
    "    demo_embedding_table as embedding_table,\n",
    ")\n",
    "from functools import partial\n",
    "\n",
    "show = partial(print, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e91492",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "Neural networks deal in numbers, not language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d15d1",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d90678",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_token_mapping(\n",
    "    'token->id',\n",
    "    tokenizer,\n",
    "    data='Tokenizers convert text to integer IDs the model can understand, breaking words or subwords into consistent units. Numbers are weird: 12345',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_token_mapping(\n",
    "    'id->token', tokenizer, data=chain(range(0, 5), range(3000, 3005), range(40473, 40478))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb3f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(tokenizer.vocab_size, gpt.transformer.tokens_embed, gpt.transformer.positions_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e199ae6",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f216622",
   "metadata": {},
   "source": [
    "#### What are they?\n",
    "\n",
    "`King - Man + Woman = Queen` (shout out Word2Vec)\n",
    "\n",
    "![word2vec](assets/word2vec.png)\n",
    "\n",
    "Learned vector representations where magnitude and direction have meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = gpt.transformer.tokens_embed.weight[3001]\n",
    "show(token_embedding.shape, token_embedding, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f51afa",
   "metadata": {},
   "source": [
    "### H_0\n",
    "\n",
    "![gpt1math](assets/h0math.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20317fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer('G P T', return_tensors='pt')\n",
    "show(tokens.input_ids, tokens.input_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1506b28",
   "metadata": {},
   "source": [
    "##### How does a matrix multiply get us the embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611023f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10s, 30s, 50s\n",
    "\n",
    "token_indicies = torch.tensor([[1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 1]])\n",
    "\n",
    "token_indicies @ embedding_table  # '3 5' @ '5 10' => '3 10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokens.input_ids\n",
    "input_shape = input_ids.shape\n",
    "show('input_ids:', input_shape, input_ids)\n",
    "\n",
    "position_ids = gpt.transformer.position_ids[None, : input_shape[-1]]\n",
    "show('position_ids:', position_ids.shape, position_ids)\n",
    "\n",
    "inputs_embeds = gpt.transformer.tokens_embed(input_ids)\n",
    "show('inputs_embeds:', inputs_embeds.shape, inputs_embeds)\n",
    "\n",
    "position_embeds = gpt.transformer.positions_embed(position_ids)\n",
    "show('position_embeds:', position_embeds.shape, position_embeds)\n",
    "\n",
    "h_0 = inputs_embeds + position_embeds\n",
    "show('h_0:', h_0.shape, h_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissecting-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
