# GPT-1 Talk

Here are the resources used for my talk "Transformer Fundamentals with GPT-1" including:

- the notebooks we walked through: `input.ipynb` + `output.ipynb`
- the transformer pseudocode: `transformer.py`
- the slide show: `Transformer Foundations with GPT 1.pdf` (including additional resources I've found helpful)
- the hugging face transformers GPT-1 implementation can be found by digging through the virtual environment, or alternatively, here's the [GitHub link](https://github.com/huggingface/transformers/blob/1bc9ac5107ff32c0115bd0b269924455be79db64/src/transformers/models/openai/modeling_openai.py))

## Setup

You must have `uv` installed. Once you do, create the virtual environment and install dependencies with:

```bash
uv sync
```
